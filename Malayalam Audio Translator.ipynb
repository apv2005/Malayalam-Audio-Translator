{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gjXILkzrfEB"
      },
      "outputs": [],
      "source": [
        "pip install transformers gradio datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iwnAiOymrkH2"
      },
      "outputs": [],
      "source": [
        "from transformers import VitsModel, VitsTokenizer\n",
        "from transformers import SpeechT5ForTextToSpeech, SpeechT5HifiGan, SpeechT5Processor\n",
        "from transformers import pipeline\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "import gradio as gr\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YGgNG0zl_Fx"
      },
      "outputs": [],
      "source": [
        "asr_pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\")\n",
        "\n",
        "trnsl_model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "trnsl_tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "trnsl_tokenizer.src_lang = \"en_XX\"\n",
        "\n",
        "tts_model = VitsModel.from_pretrained(\"facebook/mms-tts-mal\")\n",
        "tts_tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-mal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ej5HjFxIpl1u"
      },
      "outputs": [],
      "source": [
        "target_dtype = np.int16\n",
        "max_range = np.iinfo(target_dtype).max\n",
        "translations = {}\n",
        "\n",
        "def transcribe(audio):\n",
        "    outputs = asr_pipe(audio, max_new_tokens=256, generate_kwargs={\"task\": \"translate\"})\n",
        "\n",
        "    return outputs[\"text\"]\n",
        "\n",
        "def translate(english):\n",
        "    encoded_en = trnsl_tokenizer(english,return_tensors = \"pt\" )\n",
        "    generated_tokens = trnsl_model.generate(\n",
        "        **encoded_en,\n",
        "        forced_bos_token_id=trnsl_tokenizer.lang_code_to_id[\"ml_IN\"]\n",
        "    )\n",
        "    mal_text = trnsl_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "    return mal_text\n",
        "\n",
        "def synthesise(text):\n",
        "    inputs = tts_tokenizer(text=text, return_tensors=\"pt\")\n",
        "    speech = tts_model(**inputs).waveform\n",
        "    return speech.detach()\n",
        "\n",
        "\n",
        "def speech_to_speech_translation(audio):\n",
        "    english_text = transcribe(audio)\n",
        "    translated_text = translate(english_text)\n",
        "\n",
        "    translations[english_text] = translated_text\n",
        "\n",
        "    synthesised_speech = synthesise(translated_text)\n",
        "    synthesised_speech = (synthesised_speech * 32767)\n",
        "    synthesised_speech = synthesised_speech.numpy().astype(np.int16)\n",
        "    synthesised_speech = synthesised_speech.squeeze()\n",
        "    return 16000, synthesised_speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcVkhBP-psWt"
      },
      "outputs": [],
      "source": [
        "title = \"Cascaded STST\"\n",
        "\n",
        "\n",
        "demo = gr.Blocks()\n",
        "\n",
        "mic_translate = gr.Interface(\n",
        "    fn=speech_to_speech_translation,\n",
        "    inputs=gr.Audio(sources=\"microphone\", type=\"filepath\"),\n",
        "    outputs=gr.Audio(label=\"Generated Speech\", type=\"numpy\"),\n",
        ")\n",
        "\n",
        "file_translate = gr.Interface(\n",
        "    fn=speech_to_speech_translation,\n",
        "    inputs=gr.Audio(sources=\"upload\", type=\"filepath\"),\n",
        "    outputs=gr.Audio(label=\"Generated Speech\", type=\"numpy\"),\n",
        ")\n",
        "\n",
        "with demo:\n",
        "    gr.TabbedInterface([mic_translate, file_translate], [\"Microphone\", \"Audio File\"])\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ]
}